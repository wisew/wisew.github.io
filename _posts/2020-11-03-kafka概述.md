---
layout:     post                    # 使用的布局（不需要改）
title:      kafka核心概念与常用配置           # 标题 
date:       2020-11-03              # 时间
author:     王伟                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:
    - 大数据
    - kafka	                               #标签
---
## 1. kafka的定位与应用

kafka具有高吞吐、低延迟、高可靠、可重复消费等特点，已经成为大数据流处理应用的事实标准，被广泛应用于以下场景

- 企业埋点数据的存储
- 各种传感器的数据，例如交通摄像头、工业传感器、车辆GPS等
- 日志收集的缓存队列
- 流处理任务数据源与目标源
- …...

## 2. kafka的架构

<img src="/img/bigdata/kafka-cluster.png"  width="800"  height = "400" />

### 2.1 topics与partition

topic是kafka中的一类数据，topic分为多个partition，每个partition分为leader和follower，如下图

<img src="/img/bigdata/topic存储.png"  width="800"  height = "400" />

topic和partition：每个topic有多个partition，partition为kafka生产和消费的最小粒度，partition分为leader和follower，leader负责所有的读写，follower同步leader数据，leader的选举依赖zookeeper完成

ISR：follwer存在两种情况，一种为与leader partition保持同步了的，一种是与leader partition未同步的，ISR表示单个partition保持同步的partition集合，由zookeeper存储，并注册watcher监控其变化

<img src="/img/bigdata/kafka分区.png"  width="800"  height = "300" />

每个partition为一个队列，生产者在队列尾部写入，partition也是并发的最小单元

### 2.2 kafka logs文件的存储形式

<img src="/img/bigdata/数据落盘.png"  width="800"  height = "300" />

单个partition数据落盘对于多个segment，为了减少磁盘寻址，segment包含实际的日志文件以及index文件，文件命名是以当前partition的offset值，单个segment默认大小为1G，当超过这个阈值时会生成新的segment，日志保存时间也有时间限制，默认为7天。

### 2.3 zookeeper在kafka集群的作用

- 选举kafka controller，controller职责主要如下
  - 选举partition leader和更新partition的ISR集合
  - 动态上下线broker
  - 监听topic变化
    - 当修改topic分区或者副本数时，zookeeper的watcher触发并发起partition leader和ISR集合的更新
    - topic的配置修改无需重启，立即生效

## 3 kafka生产者

<img src="/img/bigdata/kafka-producer.png"  width="800"  height = "300" />

KafkaProducer基本使用方法如下

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.IntegerSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
producer = new KafkaProducer<>(props);
if (isAsync) { // Send asynchronously
                producer.send(new ProducerRecord<>(topic,
                    messageNo,
                    messageStr), callBackFunction);
            } else { // Send synchronously
                try {
                  // 同步发送,send方法返回一个future对象
                  producer.send(new ProducerRecord<>(topic,
                        messageNo,
                        messageStr)).get();
                } catch (InterruptedException | ExecutionException e) {
                    e.printStackTrace();
                }
            }
```

### 3.1 kafka producer可靠性保证

kafka通过acks的配置来修改可靠性级别

- acks=0：producer发送之后便默认已成功
- acks=1：producer发送之后收到leader partition回复后认为是成功
- acks=-1/all：producer发送之后必须收到该partition ISR副本都同步完成后才认为成功

#### 3.1.1 at most once

```java
Properties prop = new Properties();
prop.put("acks","0");
// prop.put("acks","1");
KafkaProducer producer = new KafkaProducer(prop);
producer.send(producerRecord)
```

acks=1虽然可以保证该条消息已经发送到leader partition，但如果在follower同步完成前leader挂掉这条数据在leader重选后依然丢失了，所以acks = 1并不能保证消息不丢

#### 3.1.2 at least once

```java
Properties prop = new Properties();
prop.put("acks","-1");
KafkaProducer producer = new KafkaProducer(prop);
producer.send(producerRecord, callBackFunction)
```

当初发现发送错误时，可在callbackFunction中执行重发，由于错误的产生分为两种，一种是broker端异常，此时消息未发送到broker，故直接执行重发，保证了数据发送的有效次数唯一；另一种是broker已经收到了这条消息，但acks在返回给client时出现了异常，此时如果重新发送，便出现数据重复

#### 3.1.3 exactly once

##### 3.1.3.1 幂等性

```java
Properties props = new Properties();
props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true");
// props.put("acks", "all"); // 当 enable.idempotence 为 true，这里默认为 all
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
KafkaProducer producer = new KafkaProducer(props);
producer.send(producerRecord);
```

要实现exactly-once，只需保证客户端发送重复数据时服务端不保存即可

<img src="/img/bigdata/kafka幂等发送流程.png"  width="800"  height = "300" />

ProducerState工作流程:

1. ProducerState会默认缓存5次最新的batch，用来检查该PID发送的batch是否重复，若重复直接返回成功不会继续发往broker
2. 当batch重复性校验完成后，接下来会校验该PID，若ProducerState未缓存过该PID并且SeqNum > 0，直接抛异常；若缓存过该PID，进一步判断PID的epoch，若不同并且SeqNum > 0 ，抛异常。 

##### 3.1.3.1 事务

```java
Properties props = new Properties();
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("bootstrap.servers", "localhost:9092");
props.put("transactional.id", "test-transactional");
props.put("acks", "all");
KafkaProducer producer = new KafkaProducer(props);
producer.initTransactions();

try {
    producer.beginTransaction();
    producer.send(producerRecord);
    producer.send(producerRecord);
    producer.send(producerRecord);
    producer.commitTransaction();
} catch (ProducerFencedException e1) {
    e1.printStackTrace();
    producer.close();
} catch (KafkaException e2) {
    e2.printStackTrace();
    producer.abortTransaction();
}
producer.close();
```

幂等性只能实现写入单分区时数据不丢不重，但是不支持跨分区的exactly-once，幂等性在producer故障恢复后也会失效，因为PID在producer重启后会发生变化，幂等性是事务的基础。

kafka在提交事务前会先将本次提交的数据进行checkpoint，并且在此之前的所有提交都是exactly-once的，当某个分区提交失败时，事务abord，在任务重启之后根据设置的`transactional.id`找到之前checkpoint的数据然后重新进行事务提交操作

## 4 kafka消费者

<img src="/img/bigdata/kafka-consumer.png"  width="800"  height = "300" />

<img src="/img/bigdata/consumer-offset.png"  width="800"  height = "300" />

kafka consumer在消费模式为pull，客户端可以指定一次消费的记录数，拉取数据的阻塞时间等，同一个分区只会被同一个group下的一个consumer消费，并且不同的group下的offset是独立的，consumer消费可以自由地指定earliest、latest、offset-specified三种不同的offset重置策略，消费者也分at-most-once，at-least-once和exactly-once三种模式

<img src="/img/bigdata/consumer-at-most-once.png"  width="800"  height = "240" />

消费到数据后在处理完之前提交了offset，如果在处理数据的过程中出现异常，下次重新消费时默认为从上一次提交的offset处消费，此时部分数据未处理。

<img src="/img/bigdata/consumer-at-least-once.png"  width="800"  height = "240" />

消费到数据后先处理数据后提交offset，如果在处理数据的过程中出现异常，下次消费从上一次offset重新消费，此时上一次处理成功的部分数据会被重新处理。

<img src="/img/bigdata/consumer-exactly-once.png"  width="800"  height = "300" />

consumer在pull数据后，将offset和中间的状态值做snapshot并checkpoint到可靠的存储中，当checkpoint完成后通知相应的consumer，此时consumer提交当前的offset，当程序出现异常，重新启动时将拉取state中的上一次的状态值，重新处理数据，次数可保证从kafka到内部处理的exactly-once，当涉及到外部存储时，一般分为两种情况

1. 外部输出支持幂等性，如RDBMS，es，hbase、kudu等。此时只需要根据相关主键进行insert或者update即可满足整个流程的exactly-once
2. 如果输出仅仅支持append模式，例如kafka，此时需要保证输出源支持事务并进行两阶段提交，第一阶段将本次需要提交的数据checkpoint到临时存储，第二阶段开启事务提交这一批数据，事务aborted后应用重启只需要将临时存储中的数据重新发起事务请求即可

## 5 kafka的容错

在大数据中，大部分分布式系统设计的理论为CAP理论，即

<img src="/img/bigdata/CAP.png" align="left"  width="400"  height = "360" />

kafka的底层设计偏向于AP，即牺牲了一致性，考虑一个拥有5副本的topic，kafka没有选择过半机制(hadoop、zookeeper、hbase采用的方式)，即至少3个副本保持一致且状态为最新。kafka采用了另一种方式，即kafka在zookeeper中维护了每个partition的ISR集合，并实时监控其变化，这样ISR中只要存在一个副本数量则该partition可正常提供服务。客户端可以通过设置acks参数、buffer等参数进一步提高其吞吐量。

对于重要数据，kafka可以通过参数的配置，牺牲一部分吞吐量提升数据的保障，如更改ISR最小数量、设置acks参数等。

## 6 kafka的常用配置

| 配置名                                | 默认值        | 可选值     | 参数说明                                                     |
| ------------------------------------- | ------------- | ---------- | ------------------------------------------------------------ |
| acks                                  | 1             | 1,0,-1,all | 1:发送数据只需要leader partition确认即为成功<br />0:发送过去即成功<br />-1/all:所有ISR集合中的副本都需要确认收到 |
| min.insync.replicas                   | 1             | [1,]       | producer发送数据时，                                         |
| replica.lag.time.max.ms               | 10000         | 正数       | 当一个follower数据落后leader超过该阈值则将该follower移除ISR  |
| replica.fetch.wait.max.ms             | 500           | long       | 副本同步间隔，该值需小于replica.lag.time.max.ms              |
| retries                               | 0             | int        | 重试次数                                                     |
| enable.idempotence                    | false         | true/false | 是否幂等发送                                                 |
| max.in.flight.requests.per.connection | 5             | int        | 当broker处理的batch数量大于该值则阻塞后序的请求。            |
| buffer.memory                         | 33554432/32M  | long       | producer内存缓存的大小，当producer发送速度大于发送到broker的速度，可能导致生产者空间不足，send方法要么阻塞要么异常，阻塞时间超过max.block.ms则抛异常 |
| max.block.ms                          | 60000         | long       | 见buffer.memory说明                                          |
| linger.ms                             | 0             | long       | 缓存队列时间大于该值则发送到broker                           |
| batch.size                            | 16384/16KB    | int        | 单个分区缓存的最大数据，当batch.size或者linger.ms其中之一达到阈值则会立即发送 |
| listeners                             | null          | string     | DEFAULT                                                      |
| log.segment.bytes                     | 1073741824/1G | long       | 磁盘文件的segment大小                                        |
| log.retention.hours                   | 168           | int        | 日志文件保存时间                                             |

