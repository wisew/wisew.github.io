---
layout:     post                    # 使用的布局（不需要改）
title:      分类模型的评估指标               # 标题 
date:       2018-12-30              # 时间
author:     王伟                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:
    - 机器学习算法	                               #标签
    - 模型评估
---

## 混淆矩阵

四个重要指标

- TP：样本为正例，预测值也为正例
- TN：样本为正例，预测值为负例
- FP：样本为负例，预测值为正例
- FN：样本为负例，预测值为负例

![](/img/混淆矩阵.png)

上面这张图的TP=135,TN=12,FP=14,FN=135

## Accuracy、recall、precision、F1

- Accuracy

  > 模型预测的准确度,全样本范围中有预测正确的比例

  accuracy=(TP+FN)/(TP+TN+FP+FN)

- recall

  > 模型预测的正例覆盖率，正例样本中被正确预测的比例

  recall=TP/(TP+TN)

- precision

  > 模型预测正例的样本的准确率

  precision=TP/(TP+FP)

- F1

  > 综合考虑recall和precision，调和平均值的两倍

  F1=2/(1/recall+1/precision)

recall值一般反映的是查全率，也就是正例样本被查出来的比例，一般在垃圾邮件分类，欺诈数据检测，疾病检测方面作为首要的评估指标；

precision一般反映的是准确率，也就是查出来的样本中，查对的比例，一般在搜索，推荐等方面作为首要评估指标。

## AP曲线和mAP指标

> recall和precision之间的关系曲线

![](/img/AP+mAP.png)

- 一般recall值低的，precision相对会比较高，因为recall反映的是"查全率"，查的越全，则被错误查出的可能性也就越大，所以准确率会相应变低；

- 通常情况下，模型预测出的值为连续值，对于二分类任务中，则需要设置阈值，当大于阈值时预测为True，反之为False。阈值减小，recall增大，precision减小，阈值增大，recall减小，precision增大。

mAP=图形的面积，越接近1，则模型的效果越佳。

## ROC曲线和AUC值

![](/img/ROC和AUC.png)

- TPR

  > 在模型预测正确的样本下，预测值为true所占的比例

  TPR=TP/(TP+FN)

- FPR

  > 模型预测错误的样本下，预测值为true所占比例

  FPR=FP/(FP+TN)

AUC=曲线的面积，一般取值范围(0.5,1)，值越大代表模型效果越佳。