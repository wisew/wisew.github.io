---
layout:     post                    # 使用的布局（不需要改）
title:      广义线性模型               # 标题 
date:       2019-4-26              # 时间
author:     王伟                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:
    - 机器学习算法	                               #标签
---

## 指数族分布

指数族分布公式

<a href="https://www.codecogs.com/eqnedit.php?latex=p(y|\eta)=b(y)exp(\eta^TT(y)-a(\eta))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y|\eta)=b(y)exp(\eta^TT(y)-a(\eta))" title="p(y|\eta)=b(y)exp(\eta^TT(y)-a(\eta))" /></a>

b(y)：关于y的函数

T(y)：样本对应的输出，逻辑回归中为T(y)=y，softmax回归中T(y)=(1,0,0,0...)[稀疏向量]

`η`：自然参数，可以为一个值也可以为一个向量，线性模型中为*θ*^T*X

建立广义线性模型主要分为

1. 确定分布类型
   - 泊松分布：一般对统计次数建模，如预测网站访问次数
   - gamma分布和指数分布：一般统计间隔，如公交车的等待时间
   - 伯努利分布：二分类
   - 多项分布：多分类

2. 确定T(y)的形式，很多情况下T(y)=y
3. 线性规则确定出`η`
4. 求出分布参数`ϕ`与`η`的关系
5. 求出似然函数，使用梯度上升或者牛顿法求出最优解

## 逻辑回归转成指数族分布

逻辑回归y～伯努利分布

<a href="https://www.codecogs.com/eqnedit.php?latex=p(y|\phi)=\phi^y(1-\phi)^{1-y}\\&space;p(y|\phi)=exp(ylog\phi&plus;(1-y)log(1-\phi))\\&space;p(y|\phi)=exp(ylog\frac{\phi}{1-\phi}&plus;log(1-\phi))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y|\phi)=\phi^y(1-\phi)^{1-y}\\&space;p(y|\phi)=exp(ylog\phi&plus;(1-y)log(1-\phi))\\&space;p(y|\phi)=exp(ylog\frac{\phi}{1-\phi}&plus;log(1-\phi))" title="p(y|\phi)=\phi^y(1-\phi)^{1-y}\\ p(y|\phi)=exp(ylog\phi+(1-y)log(1-\phi))\\ p(y|\phi)=exp(ylog\frac{\phi}{1-\phi}+log(1-\phi))" /></a>

与指数族公式对应

<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{cases}&space;b(y)=1\\&space;T(y)=y\\&space;\eta=log\frac{\phi}{1-\phi}\Rightarrow&space;e^\eta=\frac{\phi}{1-\phi}\Rightarrow\phi=\frac{1}{1&plus;e^{-\eta}}\\&space;a(\eta)=-log(1-\phi)=-log(1-\frac{1}{1&plus;e^{-\eta}})=log(1&plus;e^\eta)&space;\end{cases}\\" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{cases}&space;b(y)=1\\&space;T(y)=y\\&space;\eta=log\frac{\phi}{1-\phi}\Rightarrow&space;e^\eta=\frac{\phi}{1-\phi}\Rightarrow\phi=\frac{1}{1&plus;e^{-\eta}}\\&space;a(\eta)=-log(1-\phi)=-log(1-\frac{1}{1&plus;e^{-\eta}})=log(1&plus;e^\eta)&space;\end{cases}\\" title="\begin{cases} b(y)=1\\ T(y)=y\\ \eta=log\frac{\phi}{1-\phi}\Rightarrow e^\eta=\frac{\phi}{1-\phi}\Rightarrow\phi=\frac{1}{1+e^{-\eta}}\\ a(\eta)=-log(1-\phi)=-log(1-\frac{1}{1+e^{-\eta}})=log(1+e^\eta) \end{cases}\\" /></a>

`ϕ`就是关于`η`的sigmod函数，逻辑回归中

<a href="https://www.codecogs.com/eqnedit.php?latex=\eta=\theta^Tx" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\eta=\theta^Tx" title="\eta=\theta^Tx" /></a>

代入p，求出似然函数，通过梯度上升或者牛顿法求出最优解。

## softmax原理

k分类问题的标签值分布：y=1,2,3…..k~多项分布

<a href="https://www.codecogs.com/eqnedit.php?latex=p(y|\phi_1,\phi_2,\phi_3...\phi_k)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y|\phi_1,\phi_2,\phi_3...\phi_k)" title="p(y|\phi_1,\phi_2,\phi_3...\phi_k)" /></a>

引入标记函数

<a href="https://www.codecogs.com/eqnedit.php?latex=T(y)_i=1\{y=i\}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?T(y)_i=1\{y=i\}" title="T(y)_i=1\{y=i\}" /></a>

T(y)的输出为一个向量，i代表向量中第i个值，如果满足{}的条件输出为1，否则输出为0，例如

T(1)=[1,0,0,0…]，T(2)=[0,1,0,0…..]

分布函数

<a href="https://www.codecogs.com/eqnedit.php?latex=p(y|\phi_1,\phi_2,\phi_3...\phi_k)=\phi_1^{T(y)_1}\phi_2^{T(y)_2}...\phi_k^{T(y)_k}\\&space;=exp(T(y)_1log\phi_1&plus;T(y)_2log\phi_2&plus;...&plus;T(y)_klog\phi_k)\\&space;=exp(\begin{bmatrix}&space;log\phi_1\\&space;log\phi_2\\&space;...\\&space;log\phi_k&space;\end{bmatrix}^TT(y))\Rightarrow\eta=\begin{bmatrix}&space;log\phi_1\\&space;log\phi_2\\&space;...\\&space;log\phi_k&space;\end{bmatrix}\Rightarrow\phi_i=e^{\eta_i}\\&space;\sum_{i=1}^k\phi_i=1\Rightarrow\sum_{i=1}^ke^{\eta_i}=1\\&space;\phi_i=e^{\eta_i}/1=e^{\eta_i}/\sum_{i=1}^ke^{\eta_i}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y|\phi_1,\phi_2,\phi_3...\phi_k)=\phi_1^{T(y)_1}\phi_2^{T(y)_2}...\phi_k^{T(y)_k}\\&space;=exp(T(y)_1log\phi_1&plus;T(y)_2log\phi_2&plus;...&plus;T(y)_klog\phi_k)\\&space;=exp(\begin{bmatrix}&space;log\phi_1\\&space;log\phi_2\\&space;...\\&space;log\phi_k&space;\end{bmatrix}^TT(y))\Rightarrow\eta=\begin{bmatrix}&space;log\phi_1\\&space;log\phi_2\\&space;...\\&space;log\phi_k&space;\end{bmatrix}\Rightarrow\phi_i=e^{\eta_i}\\&space;\sum_{i=1}^k\phi_i=1\Rightarrow\sum_{i=1}^ke^{\eta_i}=1\\&space;\phi_i=e^{\eta_i}/1=e^{\eta_i}/\sum_{i=1}^ke^{\eta_i}" title="p(y|\phi_1,\phi_2,\phi_3...\phi_k)=\phi_1^{T(y)_1}\phi_2^{T(y)_2}...\phi_k^{T(y)_k}\\ =exp(T(y)_1log\phi_1+T(y)_2log\phi_2+...+T(y)_klog\phi_k)\\ =exp(\begin{bmatrix} log\phi_1\\ log\phi_2\\ ...\\ log\phi_k \end{bmatrix}^TT(y))\Rightarrow\eta=\begin{bmatrix} log\phi_1\\ log\phi_2\\ ...\\ log\phi_k \end{bmatrix}\Rightarrow\phi_i=e^{\eta_i}\\ \sum_{i=1}^k\phi_i=1\Rightarrow\sum_{i=1}^ke^{\eta_i}=1\\ \phi_i=e^{\eta_i}/1=e^{\eta_i}/\sum_{i=1}^ke^{\eta_i}" /></a>

每一条样本的自然参数有k个，此时`η`是一个向量

<a href="https://www.codecogs.com/eqnedit.php?latex=\eta_i=\theta_i^Tx" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\eta_i=\theta_i^Tx" title="\eta_i=\theta_i^Tx" /></a>

假设样本共有n个特征，则`θ`为k*n的矩阵，矩阵的每一列代表某一个分类的权重参数，这样，对于每一条样本，它将输出一个k维向量。

单个样本的概率p

<a href="https://www.codecogs.com/eqnedit.php?latex=p_i(y_i|\theta)=(\frac{e^{\theta_1^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_1}(\frac{e^{\theta_2^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_2}&space;(\frac{e^{\theta_3^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_3}...&space;(\frac{e^{\theta_k^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_k}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_i(y_i|\theta)=(\frac{e^{\theta_1^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_1}(\frac{e^{\theta_2^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_2}&space;(\frac{e^{\theta_3^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_3}...&space;(\frac{e^{\theta_k^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_k}" title="p_i(y_i|\theta)=(\frac{e^{\theta_1^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_1}(\frac{e^{\theta_2^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_2} (\frac{e^{\theta_3^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_3}... (\frac{e^{\theta_k^Tx_i}}{\sum_{j=1}^ke^{\theta_j^Tx}})^{T(y_i)_k}" /></a>

似然函数

<a href="https://www.codecogs.com/eqnedit.php?latex=L=\prod_{i=1}^mp_i" target="_blank"><img src="https://latex.codecogs.com/gif.latex?L=\prod_{i=1}^mp_i" title="L=\prod_{i=1}^mp_i" /></a>

通过梯度上升或者牛顿法即可求出最优解。

