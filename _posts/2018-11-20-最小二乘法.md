---
layout:     post                    # 使用的布局（不需要改）
title:      最小二乘法               # 标题 
subtitle:   推导过程 #副标题
date:       2018-11-20              # 时间
author:     王伟                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 机器学习算法
    - 线性代数
    - 最小二乘法
---

## 引入：向量的投影

> 以三维向量为例(四维我还真不知道如何去画。。。)，如下图所示，A为三维空间中的一个子空间，b在A向量空间的投影为p，a1,a2为A空间的两个线性无关的向量，误差e=b-p 

![](/img/向量投影.jpg)  
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{cases}&space;pe=0\\&space;\left[&space;\begin{matrix}&space;a_1&space;&&space;a_2&space;\end{matrix}&space;\right]\hat{x}=A\hat{x}=p\\p=b-e&space;\end{cases}&space;\\\Rightarrow&space;A^Tp=A^T(b-e)&space;\\\Rightarrow&space;A^Tp=A^Tb\\\Rightarrow&space;A^TA\hat{x}=A^Tb" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{cases}&space;pe=0\\&space;\left[&space;\begin{matrix}&space;a_1&space;&&space;a_2&space;\end{matrix}&space;\right]\hat{x}=A\hat{x}=p\\p=b-e&space;\end{cases}&space;\\\Rightarrow&space;A^Tp=A^T(b-e)&space;\\\Rightarrow&space;A^Tp=A^Tb\\\Rightarrow&space;A^TA\hat{x}=A^Tb" title="\begin{cases} pe=0\\ \left[ \begin{matrix} a_1 & a_2 \end{matrix} \right]\hat{x}=A\hat{x}=p\\p=b-e \end{cases} \\\Rightarrow A^Tp=A^T(b-e) \\\Rightarrow A^Tp=A^Tb\\\Rightarrow A^TA\hat{x}=A^Tb" /></a>  
一个很重要的方程：  
<a href="https://www.codecogs.com/eqnedit.php?latex=A^TA\hat{x}=A^Tb" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A^TA\hat{x}=A^Tb" title="A^TA\hat{x}=A^Tb" /></a>  
求出x，Ax即为所求的投影向量  

## 最小二乘法

引例：  

求出(1,1),(2,2),(3,2)的最佳拟合直线。设直线为  
<a href="https://www.codecogs.com/eqnedit.php?latex=y=\theta_0&plus;\theta_1x" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y=\theta_0&plus;\theta_1x" title="y=\theta_0+\theta_1x" /></a>  
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{cases}&space;\theta_0&plus;\theta_1=1\\&space;\theta_0&plus;2\theta_1=2\\&space;\theta_0&plus;3\theta_1=2\\&space;\end{cases}\Rightarrow\left[&space;\begin{matrix}&space;1&space;&&space;1\\1&space;&&space;2\\1&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[&space;\begin{matrix}&space;1\\2\\2&space;\end{matrix}&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{cases}&space;\theta_0&plus;\theta_1=1\\&space;\theta_0&plus;2\theta_1=2\\&space;\theta_0&plus;3\theta_1=2\\&space;\end{cases}\Rightarrow\left[&space;\begin{matrix}&space;1&space;&&space;1\\1&space;&&space;2\\1&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[&space;\begin{matrix}&space;1\\2\\2&space;\end{matrix}&space;\right]" title="\begin{cases} \theta_0+\theta_1=1\\ \theta_0+2\theta_1=2\\ \theta_0+3\theta_1=2\\ \end{cases}\Rightarrow\left[ \begin{matrix} 1 & 1\\1 & 2\\1 & 3 \end{matrix} \right]\left[ \begin{matrix} \theta_0\\\theta_1 \end{matrix} \right]=\left[ \begin{matrix} 1\\2\\2 \end{matrix} \right]" /></a>   
可以理解为a1=(1,1,1)，a2=(1,2,3)，b=(1,2,2)，此时目的是求出在a1、a2的向量空间中的哪一个向量，它与目标向量b的误差为最小，很明显所求的结果向量为b在A上的投影p。  
求解：  
<a href="https://www.codecogs.com/eqnedit.php?latex=A^TA\hat{\theta}=A^Tb\\\Rightarrow&space;\left[&space;\begin{matrix}&space;1&space;&&space;1&1\\1&space;&&space;2&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;1&space;&&space;1\\1&space;&&space;2\\1&space;&&space;3&space;\end{matrix}&space;\right]\hat{x}=\left[&space;\begin{matrix}&space;1&space;&&space;1&1\\1&space;&&space;2&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;1\\2\\2&space;\end{matrix}&space;\right]&space;\\\Rightarrow&space;\left[&space;\begin{matrix}&space;3&space;&&space;6\\6&space;&&space;14&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[\begin{matrix}5\\11\end{matrix}\right]\\\Rightarrow\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[&space;\begin{matrix}&space;\frac{2}{3}\\\frac{1}{2}&space;\end{matrix}&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A^TA\hat{\theta}=A^Tb\\\Rightarrow&space;\left[&space;\begin{matrix}&space;1&space;&&space;1&1\\1&space;&&space;2&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;1&space;&&space;1\\1&space;&&space;2\\1&space;&&space;3&space;\end{matrix}&space;\right]\hat{x}=\left[&space;\begin{matrix}&space;1&space;&&space;1&1\\1&space;&&space;2&space;&&space;3&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;1\\2\\2&space;\end{matrix}&space;\right]&space;\\\Rightarrow&space;\left[&space;\begin{matrix}&space;3&space;&&space;6\\6&space;&&space;14&space;\end{matrix}&space;\right]\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[\begin{matrix}5\\11\end{matrix}\right]\\\Rightarrow\left[&space;\begin{matrix}&space;\theta_0\\\theta_1&space;\end{matrix}&space;\right]=\left[&space;\begin{matrix}&space;\frac{2}{3}\\\frac{1}{2}&space;\end{matrix}&space;\right]" title="A^TA\hat{\theta}=A^Tb\\\Rightarrow \left[ \begin{matrix} 1 & 1&1\\1 & 2 & 3 \end{matrix} \right]\left[ \begin{matrix} 1 & 1\\1 & 2\\1 & 3 \end{matrix} \right]\hat{x}=\left[ \begin{matrix} 1 & 1&1\\1 & 2 & 3 \end{matrix} \right]\left[ \begin{matrix} 1\\2\\2 \end{matrix} \right] \\\Rightarrow \left[ \begin{matrix} 3 & 6\\6 & 14 \end{matrix} \right]\left[ \begin{matrix} \theta_0\\\theta_1 \end{matrix} \right]=\left[\begin{matrix}5\\11\end{matrix}\right]\\\Rightarrow\left[ \begin{matrix} \theta_0\\\theta_1 \end{matrix} \right]=\left[ \begin{matrix} \frac{2}{3}\\\frac{1}{2} \end{matrix} \right]" /></a>  
即最佳拟合直线为  
<a href="https://www.codecogs.com/eqnedit.php?latex=y=\frac{2}{3}&plus;\frac{1}{2}x" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y=\frac{2}{3}&plus;\frac{1}{2}x" title="y=\frac{2}{3}+\frac{1}{2}x" /></a>  
![](/img/拟合直线.png)
## 最小二乘法在机器学习中的应用
现有数据集  
<a href="https://www.codecogs.com/eqnedit.php?latex=A=\left[&space;\begin{matrix}&space;a_1^1&space;&&space;a_1^2&&space;...&space;&&space;a_1^n\\a_2^1&space;&&space;a_2^2&space;&...&space;&&space;a_2^n\\&...\\a_m^1&space;&&space;a_m^2&space;&&space;...&space;&&space;a_m^n&space;\end{matrix}&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A=\left[&space;\begin{matrix}&space;a_1^1&space;&&space;a_1^2&&space;...&space;&&space;a_1^n\\a_2^1&space;&&space;a_2^2&space;&...&space;&&space;a_2^n\\&...\\a_m^1&space;&&space;a_m^2&space;&&space;...&space;&&space;a_m^n&space;\end{matrix}&space;\right]" title="A=\left[ \begin{matrix} a_1^1 & a_1^2& ... & a_1^n\\a_2^1 & a_2^2 &... & a_2^n\\&...\\a_m^1 & a_m^2 & ... & a_m^n \end{matrix} \right]" /></a>  
训练的参数  
<a href="https://www.codecogs.com/eqnedit.php?latex=\theta=\left[&space;\begin{matrix}&space;\theta_1\\\theta_2\\...\\\theta_n&space;\end{matrix}&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta=\left[&space;\begin{matrix}&space;\theta_1\\\theta_2\\...\\\theta_n&space;\end{matrix}&space;\right]" title="\theta=\left[ \begin{matrix} \theta_1\\\theta_2\\...\\\theta_n \end{matrix} \right]" /></a>  
训练集中预测特征的值  
<a href="https://www.codecogs.com/eqnedit.php?latex=b=\left[&space;\begin{matrix}&space;b_1\\b_2\\...\\b_m&space;\end{matrix}&space;\right]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?b=\left[&space;\begin{matrix}&space;b_1\\b_2\\...\\b_m&space;\end{matrix}&space;\right]" title="b=\left[ \begin{matrix} b_1\\b_2\\...\\b_m \end{matrix} \right]" /></a>  
此时问题变为求解  
<a href="https://www.codecogs.com/eqnedit.php?latex=A\theta=b" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A\theta=b" title="A\theta=b" /></a>  
的最优解   
通常情况下，机器学习的训练集有如下特征  
- 样本数量远大于特征数量
- 特征之间线性无关  
即训练数据集矩阵属于**列满秩**矩阵  
重要结论:<a href="https://www.codecogs.com/eqnedit.php?latex=A^TA" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A^TA" title="A^TA" /></a>可逆。  
证明：  
<a href="https://www.codecogs.com/eqnedit.php?latex=A^TAx=0\\\Rightarrow&space;x^TA^TAx=0\\\Rightarrow&space;(Ax)^T(Ax)=0&space;\\\Rightarrow&space;Ax=0&space;\\\Rightarrow&space;x=0" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A^TAx=0\\\Rightarrow&space;x^TA^TAx=0\\\Rightarrow&space;(Ax)^T(Ax)=0&space;\\\Rightarrow&space;Ax=0&space;\\\Rightarrow&space;x=0" title="A^TAx=0\\\Rightarrow x^TA^TAx=0\\\Rightarrow (Ax)^T(Ax)=0 \\\Rightarrow Ax=0 \\\Rightarrow x=0" /></a>   
此时求线性回归的系数时变为：  
<a href="https://www.codecogs.com/eqnedit.php?latex=A^TA\hat{x}=A^Tb\\\Rightarrow&space;\hat{x}=(A^TA)^{-1}A^Tb" target="_blank"><img src="https://latex.codecogs.com/gif.latex?A^TA\hat{x}=A^Tb\\\Rightarrow&space;\hat{x}=(A^TA)^{-1}A^Tb" title="A^TA\hat{x}=A^Tb\\\Rightarrow \hat{x}=(A^TA)^{-1}A^Tb" /></a>  
## 最小二乘法何时使用
- 选用的模型为线性模型
- 特征不是很多的时候(<10000)
