---
layout:     post                    # 使用的布局（不需要改）
title:      决策树算法               # 标题 
date:       2018-12-22              # 时间
author:     王伟                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 机器学习算法
    - 决策树
---
## 决策树的概念

- 熵值的概念

<a href="https://www.codecogs.com/eqnedit.php?latex=S=-\sum(p_ilnp_i)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?S=-\sum(p_ilnp_i)" title="S=-\sum(p_ilnp_i)" /></a>

- GINI系数

<a href="https://www.codecogs.com/eqnedit.php?latex=G=\sum(p_i(1-p_i))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?G=\sum(p_i(1-p_i))" title="G=\sum(p_i(1-p_i))" /></a>

**熵值跟GINI系数都是表示分布的不确定性，值越大表示不确定性越大，越不利于决策**

- 叶子结点

  > 不再分解的子节点

## 构建步骤

![](/img/根结点的选择.png)

根结点根据哪个特征进行分解？

1. 计算分类/预测特征的S或者G值

2. 遍历所有特征，计算信息增益率

3. 选择增益率最大的特征作为根结点的决策特征

   增益率：

<a href="https://www.codecogs.com/eqnedit.php?latex=S=-(\frac{5}{10}*ln\frac{5}{10}&plus;\frac{5}{10}*ln\frac{5}{10})=0.693\\&space;SF=-(0.7*ln0.7&plus;0.3*ln0.3)=0.611\\&space;benifit=0.7*(\frac{4}{7}*ln\frac{4}{7})&plus;0.3*(\frac{3}{7}*ln\frac{3}{7})-0.693=0.333\\&space;benirate=benifit/SF=0.333/0.611=0.545" target="_blank"><img src="https://latex.codecogs.com/gif.latex?S=-(\frac{5}{10}*ln\frac{5}{10}&plus;\frac{5}{10}*ln\frac{5}{10})=0.693\\&space;SF=-(0.7*ln0.7&plus;0.3*ln0.3)=0.611\\&space;benifit=0.7*(\frac{4}{7}*ln\frac{4}{7})&plus;0.3*(\frac{3}{7}*ln\frac{3}{7})-0.693=0.333\\&space;benirate=benifit/SF=0.333/0.611=0.545" title="S=-(\frac{5}{10}*ln\frac{5}{10}+\frac{5}{10}*ln\frac{5}{10})=0.693\\ SF=-(0.7*ln0.7+0.3*ln0.3)=0.611\\ benifit=0.7*(\frac{4}{7}*ln\frac{4}{7})+0.3*(\frac{3}{7}*ln\frac{3}{7})-0.693=0.333\\ benirate=benifit/SF=0.333/0.611=0.545" /></a>

> 增益和增益率：如果某个特征很稀疏，假设分类完每个叶子节点只有1个数据，那么该节点的熵值为0，增益率必然最大，为了降低稀疏特征的影响，将增益/特征本身的熵
>
> 连续值的处理：求出中位数进行左右的划分

## 决策树剪枝

作用：降低过拟合风险

减枝策略：

- 预剪枝：构建决策树时进行剪枝

  - 限制深度(常用)
  - 限制叶子结点个数
  - 限制叶子结点样本个数
  - 信息增益率

- 后剪枝：构建完再剪枝

<a href="https://www.codecogs.com/eqnedit.php?latex=C_\alpha(T)=C(T)&plus;\alpha|T_{leaf}|" target="_blank"><img src="https://latex.codecogs.com/gif.latex?C_\alpha(T)=C(T)&plus;\alpha|T_{leaf}|" title="C_\alpha(T)=C(T)+\alpha|T_{leaf}|" /></a>

​	C(T):<叶子结点的样本数>*<GINI系数或者熵值>

![](/img/后剪枝.png)

标记部分的值，该节点分为了三个叶子结点

<a href="https://www.codecogs.com/eqnedit.php?latex=C_\alpha(T)=0*3&plus;0*3&plus;0.4444*3&plus;\alpha*3" target="_blank"><img src="https://latex.codecogs.com/gif.latex?C_\alpha(T)=0*3&plus;0*3&plus;0.4444*3&plus;\alpha*3" title="C_\alpha(T)=0*3+0*3+0.4444*3+\alpha*3" /></a>

可以通过调整参数来设置叶子结点个数对结点损失值的影响，从而调整决策树的大小。